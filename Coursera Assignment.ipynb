{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d04d85",
   "metadata": {},
   "source": [
    "Title of the Notebook: \"Coursera Assignment\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0163ba47",
   "metadata": {},
   "source": [
    "Introduction: This Jupyter Notebook is being created as an assignment for my IBM Data Science Course offered by Coursera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d912ea",
   "metadata": {},
   "source": [
    "List of Data Science Languages:\n",
    "1. Java: While not as commonly used for direct data analysis as Python or R, Java is heavily used in big data ecosystems (like Hadoop and Spark) and for building large-scale data science applications and production systems.\n",
    "\n",
    "2. MATLAB: Primarily used in academia and industry for numerical computation, algorithm development, and data analysis. It's particularly strong in areas like signal processing, image processing, and control systems.\n",
    "\n",
    "3. SAS: A commercial software suite for advanced analytics, business intelligence, and data management. While proprietary, SAS is still widely used in large enterprises, especially in the finance and pharmaceutical industries.\n",
    "\n",
    "4. Go (Golang): While not a primary data science language, Go is sometimes used for building high-performance data pipelines and services due to its efficiency and concurrency features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df86513",
   "metadata": {},
   "source": [
    "Data Science Libraries:\n",
    "Data science relies heavily on a vast ecosystem of libraries that extend the capabilities of programming languages, making complex tasks more manageable. While many languages have their own libraries, Python and R dominate the data science landscape due to their extensive and mature library offerings.\n",
    "\n",
    "\n",
    "# 1. Python Libraries for Data Science\n",
    "\n",
    "Python boasts an incredibly rich set of libraries, making it a go-to language for many data scientists.\n",
    "\n",
    "1. Numerical Computation and Data Structures:\n",
    "\n",
    "* NumPy: The fundamental package for scientific computing with Python. It provides support for large, multi-dimensional arrays and matrices, along with a collection of high-level mathematical functions to operate on these arrays. It's the building block for many other data science libraries.\n",
    "\n",
    "* Pandas: Built on top of NumPy, Pandas provides powerful, flexible, and easy-to-use data structures (especially DataFrames) and data analysis tools. It's essential for data cleaning, manipulation, analysis, and handling missing data.\n",
    "\n",
    "* SciPy: A collection of algorithms and functions built on the NumPy extension. It offers modules for optimization, linear algebra, integration, interpolation, special functions, Fourier transforms, signal and image processing, and other scientific and engineering tasks.\n",
    "\n",
    "* Dask: Designed for scalable analytics, Dask provides parallel computing capabilities for larger-than-memory datasets, often integrating with NumPy and Pandas.\n",
    "\n",
    "2. Data Visualization:\n",
    "\n",
    "* Matplotlib: The most widely used and foundational plotting library in Python. It provides a highly flexible platform for creating static, animated, and interactive visualizations.\n",
    "\n",
    "* Seaborn: Built on Matplotlib, Seaborn provides a high-level interface for drawing attractive and informative statistical graphics. It simplifies the creation of complex visualizations and integrates well with Pandas DataFrames.\n",
    "\n",
    "* Plotly: A powerful library for creating interactive, publication-quality graphs and dashboards. It supports a wide range of chart types and can be used for web-based visualizations.\n",
    "\n",
    "* Bokeh: Another interactive visualization library that targets modern web browsers for presentation. It allows for creating highly interactive plots, dashboards, and data applications.\n",
    "\n",
    "* Altair: A declarative statistical visualization library based on Vega-Lite. It focuses on simplifying the process of creating beautiful and effective statistical charts.\n",
    "\n",
    "3. Machine Learning:\n",
    "\n",
    "* Scikit-learn: A comprehensive and widely used machine learning library that provides a consistent interface to a wide range of supervised and unsupervised learning algorithms, including classification, regression, clustering, dimensionality reduction, model selection, and preprocessing.\n",
    "\n",
    "* TensorFlow: An open-source machine learning framework developed by Google. It's especially popular for deep learning and neural networks, allowing for the construction and training of complex models.\n",
    "\n",
    "* Keras: A high-level neural networks API, Keras can run on top of TensorFlow (or other backends like Theano or CNTK). It's designed for fast experimentation with deep neural networks.\n",
    "\n",
    "* PyTorch: An open-source machine learning library developed by Facebook's AI Research lab. It's also widely used for deep learning, known for its flexibility and dynamic computational graph.\n",
    "\n",
    "* XGBoost, LightGBM, CatBoost: These are highly optimized gradient boosting libraries, known for their speed and performance in structured data tasks and machine learning competitions.\n",
    "\n",
    "* Statsmodels: A library that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests and statistical data exploration.\n",
    "\n",
    "4. Natural Language Processing (NLP):\n",
    "\n",
    "* NLTK (Natural Language Toolkit): A leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning.\n",
    "\n",
    "* spaCy: Designed for production use, spaCy is an industrial-strength NLP library for advanced natural language processing, offering fast and efficient processing for a variety of tasks.\n",
    "\n",
    "* Gensim: A robust open-source vector space modeling and topic modeling toolkit, primarily for handling large text corpora.\n",
    "\n",
    "* Hugging Face Transformers: A powerful library providing state-of-the-art pre-trained models for various NLP tasks (e.g., text classification, translation, question answering).\n",
    "\n",
    "5. Web Scraping and Data Acquisition:\n",
    "\n",
    "* Scrapy: An open-source framework for extracting data from websites. It's a fast and powerful web crawling and web scraping framework.\n",
    "\n",
    "* Beautiful Soup: A Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree.\n",
    "\n",
    "* Requests: A simple yet elegant HTTP library for Python, used for making web requests and interacting with APIs.\n",
    "\n",
    "\n",
    "# 2. R Libraries for Data Science\n",
    "\n",
    "R is particularly strong in statistical analysis and visualization, with a comprehensive set of packages.\n",
    "\n",
    "1. Data Manipulation and Wrangling:\n",
    "\n",
    "* dplyr: A grammar of data manipulation, providing a consistent set of verbs (like `select()`, `filter()`, `mutate()`, `group_by()`, `summarize()`) that simplify data transformation.\n",
    "\n",
    "* tidyr: Works seamlessly with `dplyr` to help you create \"tidy\" data, which is a specific way of structuring data that makes analysis easier. Functions like `pivot_wider()` and `pivot_longer()` are key.\n",
    "\n",
    "* data.table: A powerful and extremely fast package for working with tabular data. It's known for its high performance when dealing with large datasets.\n",
    "\n",
    "2. Data Visualization:\n",
    "\n",
    "* ggplot2: Based on the \"grammar of graphics,\" ggplot2 is renowned for its elegant and highly customizable data visualizations. It allows you to build plots layer by layer.\n",
    "\n",
    "* R shiny: A framework for building interactive web applications directly from R, allowing you to create dynamic dashboards and data exploration tools.\n",
    "\n",
    "* plotly (for R): An R interface to Plotly.js, enabling interactive, web-based visualizations similar to its Python counterpart.\n",
    "\n",
    "3. Machine Learning and Statistical Modeling:\n",
    "\n",
    "* caret (Classification and Regression Training): A comprehensive package that streamlines the model training process, providing tools for data splitting, preprocessing, feature selection, model tuning, and evaluation for a wide range of machine learning algorithms.\n",
    "\n",
    "* TidyModels: A collection of R packages for modeling and machine learning using tidyverse principles. It provides a consistent framework for various modeling tasks.\n",
    "\n",
    "* randomForest: Implements Leo Breiman's Random Forest algorithm for classification and regression.\n",
    "\n",
    "* glmnet: For fitting generalized linear models with lasso or elasticnet regularization.\n",
    "\n",
    "* TensorFlow for R / Keras for R: R interfaces to the TensorFlow and Keras deep learning frameworks, allowing R users to leverage the power of deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2333897a",
   "metadata": {},
   "source": [
    "# Data Science Tools: A Comprehensive Table\n",
    "\n",
    "This table categorizes and lists popular data science tools, providing a brief description and highlighting their key features or use cases.\n",
    "\n",
    "| Category                            | Tool Name                 | Description                                                                                                                                                                                                                                | Key Features / Use Cases                                                                                                                                                                                                   |\n",
    "| :---------------------------------- | :------------------------ | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Programming Languages & IDEs** | **Python** | A versatile, high-level programming language widely used for data manipulation, analysis, machine learning, deep learning, and web development.                                                                                             | - Extensive libraries (NumPy, Pandas, Scikit-learn, TensorFlow, PyTorch) <br> - Large community support <br> - Readability and ease of use                                                                                    |\n",
    "|                                     | **R** | A language and environment for statistical computing and graphics, particularly popular for statistical analysis, visualization, and academic research.                                                                                              | - Strong statistical capabilities <br> - Excellent for data visualization (ggplot2) <br> - Comprehensive packages for various statistical models                                                                             |\n",
    "|                                     | **SQL** | Structured Query Language, used for managing and querying relational databases. Essential for data extraction and manipulation.                                                                                                                | - Data retrieval, insertion, update, deletion <br> - Database management <br> - Joins and aggregations                                                                                                                    |\n",
    "|                                     | **Jupyter Notebook/Lab** | An open-source web application that allows you to create and share documents containing live code, equations, visualizations, and narrative text.                                                                                                   | - Interactive coding environment <br> - Supports multiple programming languages (Python, R, Julia) <br> - Ideal for reproducible research and sharing analyses                                                            |\n",
    "|                                     | **RStudio** | An integrated development environment (IDE) for R, providing a console, syntax-highlighting editor, plotting, history, and workspace management.                                                                                                    | - Excellent R development environment <br> - Integrated tools for package management, debugging, and project management <br> - Includes R Shiny for web app development                                                 |\n",
    "|                                     | **VS Code (with extensions)** | A lightweight but powerful source code editor that supports various programming languages, including Python and R, with extensive extensions for data science.                                                                                           | - Customizable and extensible <br> - Integrated terminal, debugging, Git integration <br> - Markdown support, Jupyter Notebook integration via extensions                                                                 |\n",
    "| **Big Data Platforms & Frameworks** | **Apache Spark** | An open-source, distributed processing system used for big data workloads. It offers in-memory processing for faster data analysis.                                                                                                        | - Supports multiple languages (Scala, Java, Python, R, SQL) <br> - Real-time processing, stream processing <br> - Machine learning library (MLlib)                                                                       |\n",
    "|                                     | **Apache Hadoop** | An open-source framework for distributed storage and processing of very large datasets across computer clusters.                                                                                                                                 | - HDFS (Hadoop Distributed File System) for storage <br> - MapReduce for distributed processing <br> - Scalability and fault tolerance                                                                                     |\n",
    "|                                     | **Databricks** | A unified analytics platform built on Apache Spark, providing a collaborative environment for data engineering, machine learning, and data warehousing.                                                                                               | - Collaborative notebooks <br> - Optimized Spark runtime <br> - MLOps features (MLflow)                                                                                                                                 |\n",
    "| **Cloud Platforms** | **AWS (Amazon Web Services)** | A comprehensive suite of cloud computing services, including tools for data storage (S3), big data analytics (EMR, Redshift), machine learning (SageMaker), and more.                                                                           | - Scalable compute and storage <br> - Managed data services <br> - Wide range of ML services and pre-trained models                                                                                                      |\n",
    "|                                     | **Google Cloud Platform (GCP)** | Google's suite of cloud computing services, offering tools like BigQuery (data warehouse), Dataflow (ETL), AI Platform (ML), and Compute Engine.                                                                                              | - Serverless data warehousing <br> - Powerful ML APIs and AutoML <br> - Global network infrastructure                                                                                                                 |\n",
    "|                                     | **Microsoft Azure** | Microsoft's cloud computing service, providing a wide range of services including Azure Synapse Analytics, Azure Databricks, Azure Machine Learning, and storage solutions.                                                                             | - Seamless integration with Microsoft ecosystem <br> - End-to-end ML platform <br> - Hybrid cloud capabilities                                                                                                          |\n",
    "| **Machine Learning & Deep Learning Frameworks** | **TensorFlow** | An open-source machine learning framework developed by Google, widely used for deep learning and neural networks.                                                                                                                  | - Flexible architecture <br> - Strong community support <br> - Scalable for large-scale deployments                                                                                                                      |\n",
    "|                                     | **PyTorch** | An open-source machine learning library developed by Facebook, known for its flexibility and dynamic computational graphs, popular in research and development.                                                                                           | - Intuitive API <br> - Dynamic computation graphs <br> - Strong for research and prototyping <br> - Eager execution for easier debugging                                                                                        |\n",
    "|                                     | **Scikit-learn** | A popular Python library for traditional machine learning algorithms, offering tools for classification, regression, clustering, dimensionality reduction, and more.                                                                                       | - Consistent API <br> - Broad range of algorithms <br> - Easy to use for beginners and experts                                                                                                                          |\n",
    "|                                     | **Keras** | A high-level neural networks API that can run on top of TensorFlow, Theano, or CNTK, designed for fast experimentation with deep neural networks.                                                                                                       | - User-friendly and modular <br> - Rapid prototyping <br> - Supports various neural network architectures                                                                                                             |\n",
    "| **Data Visualization Tools** | **Tableau** | A powerful and intuitive business intelligence tool for creating interactive data visualizations, dashboards, and reports.                                                                                                                       | - Drag-and-drop interface <br> - Wide range of chart types <br> - Connects to various data sources                                                                                                                        |\n",
    "|                                     | **Power BI** | Microsoft's business intelligence tool that enables users to create interactive dashboards and reports from various data sources.                                                                                                                    | - Integrates with Microsoft products <br> - Strong data modeling capabilities <br> - Easy sharing and collaboration                                                                                                    |\n",
    "|                                     | **Qlik Sense** | A self-service data discovery and visualization application that allows users to create flexible, interactive visualizations and apps.                                                                                                                | - Associative engine for data exploration <br> - Interactive dashboards <br> - Governed self-service BI                                                                                                                 |\n",
    "| **Version Control** | **Git** | A distributed version control system used for tracking changes in source code during software development, essential for collaborative data science projects.                                                                                             | - Tracks changes in code <br> - Facilitates collaboration <br> - Branching and merging capabilities                                                                                                                    |\n",
    "|                                     | **GitHub / GitLab / Bitbucket** | Web-based platforms that provide hosting for Git repositories, along with features for collaboration, code review, and project management.                                                                                                 | - Remote Git repository hosting <br> - Issue tracking, pull requests <br> - CI/CD pipeline integration                                                                                                                    |\n",
    "| **Deployment & MLOps** | **Docker** | A platform for developing, shipping, and running applications in containers, enabling consistent environments for data science models.                                                                                                             | - Environment consistency <br> - Portability across different systems <br> - Resource isolation                                                                                                                         |\n",
    "|                                     | **Kubernetes** | An open-source system for automating deployment, scaling, and management of containerized applications, often used for deploying machine learning models at scale.                                                                                     | - Container orchestration <br> - Automated deployment and scaling <br> - Self-healing capabilities                                                                                                                      |\n",
    "|                                     | **MLflow** | An open-source platform for managing the end-to-end machine learning lifecycle, including experimentation, reproducibility, and deployment.                                                                                                            | - Experiment tracking <br> - Model packaging and deployment <br> - Reproducible runs                                                                                                                                   |\n",
    "| **Data Warehousing & Databases** | **Snowflake** | A cloud-based data warehousing platform known for its scalability, flexibility, and ability to handle structured and semi-structured data.                                                                                                         | - Separate compute and storage <br> - Multi-cloud support <br> - Data sharing and collaboration                                                                                                                        |\n",
    "|                                     | **Amazon Redshift** | A fast, fully managed, petabyte-scale cloud data warehouse service by AWS.                                                                                                                                                                     | - Columnar storage <br> - Massively parallel processing (MPP) <br> - Integrates with AWS ecosystem                                                                                                                   |\n",
    "|                                     | **PostgreSQL** | A powerful, open-source object-relational database system known for its reliability, feature robustness, and performance.                                                                                                                          | - ACID compliance <br> - Support for complex queries <br> - Extensible                                                                                                                                                |\n",
    "| **ETL (Extract, Transform, Load)** | **Apache Airflow** | An open-source platform to programmatically author, schedule, and monitor workflows, widely used for building and managing data pipelines.                                                                                                    | - Workflow orchestration <br> - Scalable and flexible <br> - Web UI for monitoring                                                                                                                                    |\n",
    "|                                     | **Talend** | An open-source data integration platform that provides tools for ETL, data quality, data preparation, and big data integration.                                                                                                                | - Graphical development environment <br> - Connectors to various data sources <br> - Supports on-premise and cloud deployments                                                                                            |\n",
    "| **Statistical Software** | **SAS** | A commercial software suite for advanced analytics, business intelligence, and data management, widely used in large enterprises.                                                                                                                | - Robust statistical analysis <br> - Data management capabilities <br> - Reporting and business intelligence                                                                                                          |\n",
    "|                                     | **SPSS** | A statistical software suite developed by IBM for data management, advanced analytics, and business intelligence.                                                                                                                                | - User-friendly interface <br> - Comprehensive statistical procedures <br> - Data manipulation and reporting                                                                                                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ab08d",
   "metadata": {},
   "source": [
    "Arithmetic Expression Examples:\n",
    "\n",
    "Here are some examples of arithmetic expressions, categorized by the operations involved and increasing complexity:\n",
    "\n",
    "**Basic Operations:**\n",
    "\n",
    "* **Addition:**\n",
    "    * $5 + 3$\n",
    "    * $12.5 + 7.2$\n",
    "    * $100 + 20 + 5$\n",
    "* **Subtraction:**\n",
    "    * $9 - 4$\n",
    "    * $25.0 - 8.5$\n",
    "    * $50 - 10 - 5$\n",
    "* **Multiplication:**\n",
    "    * $6 \\times 7$ (or $6 * 7$)\n",
    "    * $3.1 \\times 2.0$\n",
    "    * $4 \\times 5 \\times 2$\n",
    "* **Division:**\n",
    "    * $10 / 2$\n",
    "    * $15.0 / 3.0$\n",
    "    * $100 / 4 / 5$\n",
    "\n",
    "**Expressions with Multiple Operations (Order of Operations - PEMDAS/BODMAS):**\n",
    "\n",
    "* **Parentheses/Brackets First:**\n",
    "    * $(2 + 3) \\times 4$\n",
    "    * $10 / (5 - 3)$\n",
    "    * $2 \\times (7 + 1) - 5$\n",
    "* **Exponents/Orders:**\n",
    "    * $2^3 + 5$ (meaning $2 \\times 2 \\times 2 + 5$)\n",
    "    * $9 - 3^2$\n",
    "    * $(4 + 1)^2 / 5$\n",
    "* **Mixed Operations:**\n",
    "    * $5 + 3 \\times 2$ (Multiplication before addition)\n",
    "    * $10 - 6 / 2$ (Division before subtraction)\n",
    "    * $(8 - 4) \\times 2 + 7$\n",
    "    * $25 / 5 + 3 \\times (7 - 2)$\n",
    "    * $100 - (2^3 + 4) \\times 5 / 2$\n",
    "\n",
    "**Expressions with Variables (Algebraic Expressions):**\n",
    "\n",
    "While strictly speaking, these are algebraic expressions, they become arithmetic expressions once values are substituted for the variables.\n",
    "\n",
    "* $x + 5$ (If $x = 3$, then $3 + 5$)\n",
    "* $2y - 7$ (If $y = 10$, then $2 \\times 10 - 7$)\n",
    "* $a^2 + b^2$ (If $a = 3, b = 4$, then $3^2 + 4^2$)\n",
    "* $(p + q) / r$ (If $p = 6, q = 2, r = 4$, then $(6 + 2) / 4$)\n",
    "\n",
    "**Key Characteristics of Arithmetic Expressions:**\n",
    "\n",
    "* They consist of numbers (operands) and arithmetic operators ($+, -, \\times, /, \\text{exponents}$).\n",
    "* They can include parentheses to dictate the order of operations.\n",
    "* They evaluate to a single numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a60fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplication:\n",
      "10 * 5 = 50\n",
      "------------------------------\n",
      "Cost of 3 items at $15.75 each = $47.25\n",
      "------------------------------\n",
      "Addition:\n",
      "25 + 12 = 37\n",
      "------------------------------\n",
      "Total score from three tests (80, 95, 70) = 245\n",
      "------------------------------\n",
      "Combined Operations:\n",
      "Cost of Item A (2 * $7.5) = $15.00\n",
      "Cost of Item B (4 * $3.25) = $13.00\n",
      "Grand Total = $28.00\n"
     ]
    }
   ],
   "source": [
    "# Define two numbers for multiplication\n",
    "num1_mul = 10\n",
    "num2_mul = 5\n",
    "\n",
    "# Perform multiplication\n",
    "result_mul = num1_mul * num2_mul\n",
    "\n",
    "# Print the result of multiplication\n",
    "print(f\"Multiplication:\")\n",
    "print(f\"{num1_mul} * {num2_mul} = {result_mul}\")\n",
    "print(\"-\" * 30) # Separator for clarity\n",
    "\n",
    "# Another example with floating-point numbers\n",
    "price = 15.75\n",
    "quantity = 3\n",
    "total_cost = price * quantity\n",
    "print(f\"Cost of {quantity} items at ${price} each = ${total_cost:.2f}\") # Format to 2 decimal places\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Define two numbers for addition\n",
    "num1_add = 25\n",
    "num2_add = 12\n",
    "\n",
    "# Perform addition\n",
    "result_add = num1_add + num2_add\n",
    "\n",
    "# Print the result of addition\n",
    "print(f\"Addition:\")\n",
    "print(f\"{num1_add} + {num2_add} = {result_add}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Another example with multiple numbers\n",
    "score1 = 80\n",
    "score2 = 95\n",
    "score3 = 70\n",
    "total_score = score1 + score2 + score3\n",
    "print(f\"Total score from three tests ({score1}, {score2}, {score3}) = {total_score}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "item_a_count = 2\n",
    "item_a_price = 7.50\n",
    "\n",
    "item_b_count = 4\n",
    "item_b_price = 3.25\n",
    "\n",
    "# Calculate cost of item A\n",
    "cost_a = item_a_count * item_a_price\n",
    "\n",
    "# Calculate cost of item B\n",
    "cost_b = item_b_count * item_b_price\n",
    "\n",
    "# Calculate total cost\n",
    "grand_total = cost_a + cost_b\n",
    "\n",
    "print(f\"Combined Operations:\")\n",
    "print(f\"Cost of Item A ({item_a_count} * ${item_a_price}) = ${cost_a:.2f}\")\n",
    "print(f\"Cost of Item B ({item_b_count} * ${item_b_price}) = ${cost_b:.2f}\")\n",
    "print(f\"Grand Total = ${grand_total:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28ab2cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 minutes is equal to 2.0 hours.\n",
      "------------------------------\n",
      "45 minutes is equal to 0.75 hours.\n",
      "------------------------------\n",
      "210 minutes is equal to 3.5 hours.\n",
      "------------------------------\n",
      "Enter the number of minutes to convert to hours: 78\n",
      "78.0 minutes is equal to 1.3 hours.\n"
     ]
    }
   ],
   "source": [
    "def convert_minutes_to_hours(minutes):\n",
    "  \"\"\"\n",
    "  Converts a duration from minutes to hours.\n",
    "\n",
    "  Args:\n",
    "    minutes (float or int): The number of minutes to convert.\n",
    "\n",
    "  Returns:\n",
    "    float: The equivalent number of hours.\n",
    "  \"\"\"\n",
    "\n",
    "  hours = minutes / 60\n",
    "  return hours\n",
    "\n",
    "# Example 1: Convert a whole number of minutes\n",
    "minutes_1 = 120\n",
    "hours_1 = convert_minutes_to_hours(minutes_1)\n",
    "print(f\"{minutes_1} minutes is equal to {hours_1} hours.\")\n",
    "print(\"-\" * 30) # Separator\n",
    "\n",
    "# Example 2: Convert a fractional number of minutes\n",
    "minutes_2 = 45\n",
    "hours_2 = convert_minutes_to_hours(minutes_2)\n",
    "print(f\"{minutes_2} minutes is equal to {hours_2} hours.\")\n",
    "print(\"-\" * 30) # Separator\n",
    "\n",
    "# Example 3: Convert a larger number of minutes\n",
    "minutes_3 = 210\n",
    "hours_3 = convert_minutes_to_hours(minutes_3)\n",
    "print(f\"{minutes_3} minutes is equal to {hours_3} hours.\")\n",
    "print(\"-\" * 30) # Separator\n",
    "\n",
    "# Example 4: Get input from the user for conversion\n",
    "try:\n",
    "  user_minutes_str = input(\"Enter the number of minutes to convert to hours: \")\n",
    "  user_minutes = float(user_minutes_str) # Convert input string to a floating-point number\n",
    "\n",
    "  if user_minutes < 0:\n",
    "    print(\"Minutes cannot be negative. Please enter a non-negative value.\")\n",
    "  else:\n",
    "    user_hours = convert_minutes_to_hours(user_minutes)\n",
    "    print(f\"{user_minutes} minutes is equal to {user_hours} hours.\")\n",
    "except ValueError:\n",
    "  print(\"Invalid input. Please enter a numerical value for minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ccd99e",
   "metadata": {},
   "source": [
    "Ojective:\n",
    "    \n",
    "    Common Objectives and Uses for Jupyter Notebooks\n",
    "Jupyter Notebooks serve as interactive computing environments that combine code, output, visualizations, and narrative text in a single document. Their primary objectives often revolve around:\n",
    "\n",
    "Exploratory Data Analysis (EDA):\n",
    "\n",
    "Objective: To understand the characteristics of a dataset, identify patterns, detect anomalies, and test hypotheses.\n",
    "\n",
    "How: By writing code to load data, clean it, calculate statistics, and create various plots and charts, all interspersed with explanations.\n",
    "\n",
    "Data Cleaning and Preprocessing:\n",
    "\n",
    "Objective: To transform raw data into a clean, usable format for analysis or modeling.\n",
    "\n",
    "How: Implementing Python (or R/Julia) code to handle missing values, remove duplicates, correct errors, format data types, and scale features.\n",
    "\n",
    "Machine Learning Model Development:\n",
    "\n",
    "Objective: To build, train, evaluate, and fine-tune machine learning models.\n",
    "\n",
    "How: Using libraries like scikit-learn, TensorFlow, or PyTorch to define models, train them on data, make predictions, and assess performance metrics.\n",
    "\n",
    "Statistical Modeling and Hypothesis Testing:\n",
    "\n",
    "Objective: To apply statistical methods, build regressions, and conduct statistical tests to draw inferences from data.\n",
    "\n",
    "How: Employing libraries like SciPy or StatsModels to perform t-tests, ANOVA, linear regression, etc., and interpret the results alongside the code.\n",
    "\n",
    "Data Visualization:\n",
    "\n",
    "Objective: To create compelling and insightful visual representations of data to communicate findings effectively.\n",
    "\n",
    "How: Utilizing libraries such as Matplotlib, Seaborn, Plotly, or Bokeh to generate static, interactive, or animated plots embedded directly within the notebook.\n",
    "\n",
    "Literate Programming and Reproducible Research:\n",
    "\n",
    "Objective: To create documents that clearly explain the thought process, methodology, and results of an analysis, making it easy for others (and your future self) to reproduce.\n",
    "\n",
    "How: Combining executable code, its output, and rich text (Markdown) explanations, equations (LaTeX), and images in a single, shareable file.\n",
    "\n",
    "Teaching and Learning:\n",
    "\n",
    "Objective: To present educational content in an interactive format, allowing learners to execute code, modify it, and see immediate results.\n",
    "\n",
    "How: Creating tutorials, exercises, and examples where theoretical concepts are immediately put into practice with live code demonstrations.\n",
    "\n",
    "Prototyping and Experimentation:\n",
    "\n",
    "Objective: To quickly test new ideas, algorithms, or approaches in an iterative and flexible environment.\n",
    "\n",
    "How: The cell-by-cell execution allows for rapid iteration and debugging, making it ideal for experimental development.\n",
    "\n",
    "Reporting and Storytelling:\n",
    "\n",
    "Objective: To share analytical results and insights with a non-technical audience in a clear and engaging manner.\n",
    "\n",
    "How: Notebooks can be converted into various formats (HTML, PDF, slides), serving as dynamic reports that tell a data story.\n",
    "\n",
    "Web Scraping and API Interaction:\n",
    "\n",
    "Objective: To programmatically collect data from websites or interact with web services.\n",
    "\n",
    "How: Writing Python code using libraries like BeautifulSoup, Requests, or Pandas to fetch and parse data from the web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df0f550",
   "metadata": {},
   "source": [
    "# Author: Aniket Mishra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d55611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
